{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b8efb8-21ca-4eb1-95bd-6af6f256b000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable pubsub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e250b0-bcf5-491a-b84d-5192dcb99440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud services enable dataflow.googleapis.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7873a9d6-0caa-4611-9062-11f2866e1cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jupyter/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting apache-beam[gcp]\n",
      "  Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam[gcp])\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache-beam[gcp])\n",
      "  Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam[gcp])\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cloudpickle~=2.2.1 (from apache-beam[gcp])\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting fastavro<2,>=0.23.6 (from apache-beam[gcp])\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam[gcp])\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam[gcp])\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp])\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (4.23.0)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam[gcp])\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.25.2)\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam[gcp])\n",
      "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (24.1)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam[gcp])\n",
      "  Downloading pymongo-4.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.20.3)\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam[gcp])\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2024.2)\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam[gcp])\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting regex>=2020.6.8 (from apache-beam[gcp])\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.32.3)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache-beam[gcp])\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.23.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (6.0.2)\n",
      "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.6)\n",
      "Requirement already satisfied: cachetools<6,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (5.5.0)\n",
      "Collecting google-api-core<3,>=2.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-apitools<0.5.32,>=0.5.31 (from apache-beam[gcp])\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.36.0)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (0.2.0)\n",
      "Collecting google-cloud-datastore<3,>=2.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_pubsub-2.28.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting google-cloud-storage<3,>=2.18.2 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: google-cloud-bigquery<4,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.27.0)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.4.1)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_bigtable-2.29.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_spanner-3.52.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_dlp-3.28.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: google-cloud-language<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (2.15.1)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_videointelligence-2.16.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_vision-3.10.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp])\n",
      "  Downloading google_cloud_recommendations_ai-0.10.16-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0,>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.73.0)\n",
      "Requirement already satisfied: keyrings.google-artifactregistry-auth in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]) (1.1.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3,>=2.0.0->apache-beam[gcp]) (1.66.0)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (4.1.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]) (4.9)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.13.1)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (1.10.19)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0,>=1.26.0->apache-beam[gcp]) (0.16)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4,>=2.0.0->apache-beam[gcp]) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]) (0.13.1)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.48.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.27.0)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]) (0.5.2)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp])\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3,>=2.18.2->apache-beam[gcp]) (1.6.0)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp])\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam[gcp]) (3.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam[gcp]) (0.21.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam[gcp])\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam[gcp]) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]) (2024.8.30)\n",
      "Requirement already satisfied: keyring in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]) (25.5.0)\n",
      "Requirement already satisfied: pluggy in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]) (0.6.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (0.48b0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (4.1.0)\n",
      "Requirement already satisfied: jaraco.context in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (6.0.1)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (0.8.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]) (3.21.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in /opt/conda/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (43.0.3)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (10.5.0)\n",
      "Requirement already satisfied: backports.tarfile in /opt/conda/lib/python3.10/site-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]) (2.22)\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m355.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Downloading google_cloud_bigtable-2.29.0-py2.py3-none-any.whl (445 kB)\n",
      "Downloading google_cloud_datastore-2.20.2-py2.py3-none-any.whl (197 kB)\n",
      "Downloading google_cloud_dlp-3.28.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_cloud_pubsub-2.28.0-py2.py3-none-any.whl (301 kB)\n",
      "Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading google_cloud_recommendations_ai-0.10.16-py2.py3-none-any.whl (209 kB)\n",
      "Downloading google_cloud_spanner-3.52.0-py2.py3-none-any.whl (449 kB)\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Downloading google_cloud_videointelligence-2.16.0-py2.py3-none-any.whl (272 kB)\n",
      "Downloading google_cloud_vision-3.10.0-py2.py3-none-any.whl (523 kB)\n",
      "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m182.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "Downloading orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading pymongo-4.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m483.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-5.2.1-py3-none-any.whl (261 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m402.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading apache_beam-2.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m179.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: crcmod, dill, google-apitools, hdfs, docopt\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23540 sha256=e34a0a977b930fbc7d6dc28834f6ea559c361c4553219889b5a3ad1f7bd1fae9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rojwjq_b/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=aaf8981208d4fa0ed8bebe16f967703faaead42c0880ec6b9a98bb5a2e7f8ea5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rojwjq_b/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131015 sha256=62a1ac1f4dd33338f3d427e4d62c194c595e3ee6b59170471acede941425d13c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rojwjq_b/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=e31e4083acdb667f944fe568a3d4244f8a204feea52638c84498af89b5ddd89d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rojwjq_b/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=7edb5f1ecc689d8822cc53afd6195e5894f1df56591a7f867ae3e96334d7f7de\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rojwjq_b/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built crcmod dill google-apitools hdfs docopt\n",
      "Installing collected packages: sortedcontainers, docopt, crcmod, regex, redis, pydot, orjson, objsize, jsonpickle, grpcio, fasteners, fastavro, dnspython, dill, cloudpickle, pymongo, hdfs, grpc-interceptor, google-apitools, google-api-core, apache-beam, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-pubsublite\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.68.0\n",
      "    Uninstalling grpcio-1.68.0:\n",
      "      Successfully uninstalled grpcio-1.68.0\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.1.0\n",
      "    Uninstalling cloudpickle-3.1.0:\n",
      "      Successfully uninstalled cloudpickle-3.1.0\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "  Attempting uninstall: google-cloud-datastore\n",
      "    Found existing installation: google-cloud-datastore 1.15.5\n",
      "    Uninstalling google-cloud-datastore-1.15.5:\n",
      "      Successfully uninstalled google-cloud-datastore-1.15.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed apache-beam-2.63.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 google-api-core-2.24.1 google-apitools-0.5.31 google-cloud-bigtable-2.29.0 google-cloud-datastore-2.20.2 google-cloud-dlp-3.28.0 google-cloud-pubsub-2.28.0 google-cloud-pubsublite-1.12.0 google-cloud-recommendations-ai-0.10.16 google-cloud-spanner-3.52.0 google-cloud-storage-2.19.0 google-cloud-videointelligence-2.16.0 google-cloud-vision-3.10.0 grpc-interceptor-0.15.4 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 objsize-0.7.1 orjson-3.10.15 pydot-1.4.2 pymongo-4.11.1 redis-5.2.1 regex-2024.11.6 sortedcontainers-2.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install apache-beam[gcp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114cbdd1-4362-4f90-98b9-fe1349e366fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.runners import DataflowRunner\n",
    "from apache_beam.transforms import trigger\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.io import WriteToBigQuery\n",
    "from apache_beam.io import BigQueryDisposition\n",
    "import google.auth\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecf7197-7883-4a9f-9323-d7af20a47ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from apache_beam.options.pipeline_options import PipelineOptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a5907f-ba00-4858-bc7d-c49bb09ea4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PipelineOptions(\n",
    "    runner='DataflowRunner',  # Use 'DirectRunner' for local execution\n",
    "    project='customer-churn-451414',\n",
    "    region='asia-southeast1',\n",
    "    temp_location='gs://customer-churn-storage-bucket/temp',\n",
    "    staging_location='gs://customer-churn-storage-bucket/staging',\n",
    "    job_name='dataflow-etl-job'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d667c6f8-27f7-4924-9c9c-970d34761731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "creation_time: 2025-02-19T14:03:29+0000\n",
      "default_storage_class: STANDARD\n",
      "generation: 1739973807725754051\n",
      "location: ASIA\n",
      "location_type: multi-region\n",
      "metageneration: 2\n",
      "name: customer-churn-storage-bucket\n",
      "public_access_prevention: inherited\n",
      "rpo: DEFAULT\n",
      "soft_delete_policy:\n",
      "  retentionDurationSeconds: '0'\n",
      "storage_url: gs://customer-churn-storage-bucket/\n",
      "uniform_bucket_level_access: true\n",
      "update_time: 2025-02-25T14:19:41+0000\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage buckets list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9467325-fa35-4756-b777-1e00c149ef18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creation_time: 2025-02-19T14:03:29+0000\n",
      "default_storage_class: STANDARD\n",
      "generation: 1739973807725754051\n",
      "location: ASIA\n",
      "location_type: multi-region\n",
      "metageneration: 2\n",
      "name: customer-churn-storage-bucket\n",
      "public_access_prevention: inherited\n",
      "rpo: DEFAULT\n",
      "soft_delete_policy:\n",
      "  retentionDurationSeconds: '0'\n",
      "storage_url: gs://customer-churn-storage-bucket/\n",
      "uniform_bucket_level_access: true\n",
      "update_time: 2025-02-25T14:19:41+0000\n"
     ]
    }
   ],
   "source": [
    "!gcloud storage buckets describe gs://customer-churn-storage-bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dad42a9-56ae-498a-bee4-177b6ec99c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:Discarding unparseable args: ['-f', '/home/jupyter/.local/share/jupyter/runtime/kernel-b89ee8fb-dfd6-4ff3-ac11-c4733f68ff6a.json']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    div.alert {\n",
       "      white-space: pre-line;\n",
       "    }\n",
       "  </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
       "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://customer-churn-storage-bucket/staging/dataflow-etl-job.1740662613.627454 for cache location.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jupyter/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mWARNING:apache_beam.options.pipeline_options:Unknown pipeline options received: -f,/home/jupyter/.local/share/jupyter/runtime/kernel-b89ee8fb-dfd6-4ff3-ac11-c4733f68ff6a.json. Ignore if flags are used for internal purposes.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n",
      "WARNING:apache_beam.options.pipeline_options:Unknown pipeline options received: -f,/home/jupyter/.local/share/jupyter/runtime/kernel-b89ee8fb-dfd6-4ff3-ac11-c4733f68ff6a.json. Ignore if flags are used for internal purposes.\n",
      "WARNING:apache_beam.options.pipeline_options:Discarding flag -f, single dash flags are not allowed.\n",
      "ERROR:apache_beam.runners.dataflow.dataflow_runner:2025-02-27T13:27:02.322Z: JOB_MESSAGE_ERROR: Startup of the worker pool in zone asia-southeast1-a failed to bring up any of the desired 1 workers. Please refer to https://cloud.google.com/dataflow/docs/guides/common-errors#worker-pool-failure for help troubleshooting. ZONE_RESOURCE_POOL_EXHAUSTED: Instance 'dataflow-etl-job-02270526-1l4n-harness-7j1q' creation failed: The zone 'projects/customer-churn-451414/zones/asia-southeast1-a' does not have enough resources available to fulfill the request.  Try a different zone, or try again later.\n",
      "ERROR:apache_beam.runners.dataflow.dataflow_runner:2025-02-27T13:27:02.339Z: JOB_MESSAGE_ERROR: Workflow failed.\n",
      "WARNING:apache_beam.runners.dataflow.dataflow_runner:2025-02-27T13:27:02.511Z: JOB_MESSAGE_WARNING: Unable to delete temp files: \"gs://customer-churn-storage-bucket/temp/dataflow-etl-job.1740662613.627454/dataflow-etl-job.1740662764.248436/dax-tmp-2025-02-27_05_26_05-5644318696860845791-S01-0-b651dc0bafb48d9b/tmp-b651dc0bafb48410@DAX.sdfmeta.\"\n",
      "WARNING:apache_beam.runners.dataflow.dataflow_runner:2025-02-27T13:27:02.529Z: JOB_MESSAGE_WARNING: S01:[10]: ReadFromGCS/Read/Impulse+[10]: ReadFromGCS/Read/EmitSource+[10]: ReadFromGCS/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/PairWithRestriction+[10]: ReadFromGCS/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/SplitWithSizing failed.\n",
      "ERROR:apache_beam.runners.dataflow.dataflow_runner:Console URL: https://console.cloud.google.com/dataflow/jobs/<RegionId>/2025-02-27_05_26_05-5644318696860845791?project=<ProjectId>\n"
     ]
    },
    {
     "ename": "DataflowRuntimeException",
     "evalue": "Dataflow pipeline failed. State: FAILED, Error:\nWorkflow failed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataflowRuntimeException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(StringIO(line))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(reader)  \u001b[38;5;66;03m# Returns a list of values\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m beam\u001b[38;5;241m.\u001b[39mPipeline(options\u001b[38;5;241m=\u001b[39mpipeline_options) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m     10\u001b[0m     raw_data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     11\u001b[0m         p\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReadFromGCS\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mReadFromText(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://customer-churn-storage-bucket/Telco_Customer_Churn.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, skip_header_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;241m|\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParseCSV\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m>>\u001b[39m beam\u001b[38;5;241m.\u001b[39mMap(parse_csv)\n\u001b[1;32m     14\u001b[0m     )\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.61.0/lib/python3.10/site-packages/apache_beam/pipeline.py:622\u001b[0m, in \u001b[0;36mPipeline.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mview_as(StandardOptions)\u001b[38;5;241m.\u001b[39mno_wait_until_finish:\n\u001b[0;32m--> 622\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m   logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    625\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob execution continues without waiting for completion.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    626\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_until_finish\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in PipelineResult to block\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    627\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m until finished.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.61.0/lib/python3.10/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:807\u001b[0m, in \u001b[0;36mDataflowPipelineResult.wait_until_finish\u001b[0;34m(self, duration)\u001b[0m\n\u001b[1;32m    803\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m!=\u001b[39m PipelineState\u001b[38;5;241m.\u001b[39mDONE:\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;66;03m# TODO(BEAM-1290): Consider converting this to an error log based on\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;66;03m# theresolution of the issue.\u001b[39;00m\n\u001b[1;32m    806\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39merror(consoleUrl)\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataflowRuntimeException(\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataflow pipeline failed. State: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    809\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runner, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_error_msg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[1;32m    810\u001b[0m         \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m PipelineState\u001b[38;5;241m.\u001b[39mis_terminal(\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m PipelineState\u001b[38;5;241m.\u001b[39mFAILED \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runner:\n\u001b[1;32m    813\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m DataflowRuntimeException(\n\u001b[1;32m    814\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataflow pipeline failed. State: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    815\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runner, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_error_msg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)),\n\u001b[1;32m    816\u001b[0m       \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mDataflowRuntimeException\u001b[0m: Dataflow pipeline failed. State: FAILED, Error:\nWorkflow failed."
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    from io import StringIO\n",
    "    reader = csv.reader(StringIO(line))\n",
    "    return next(reader)  # Returns a list of values\n",
    "\n",
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    raw_data = (\n",
    "        p\n",
    "        | 'ReadFromGCS' >> beam.io.ReadFromText('gs://customer-churn-storage-bucket/Telco_Customer_Churn.csv', skip_header_lines=1)\n",
    "        | 'ParseCSV' >> beam.Map(parse_csv)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929d4d8-1385-4551-8812-0b7ea4788047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "pipeline_options = PipelineOptions([\n",
    "    '--runner=DirectRunner'  # Local execution\n",
    "])\n",
    "\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    from io import StringIO\n",
    "    reader = csv.reader(StringIO(line))\n",
    "    return next(reader)  # Returns a list of values\n",
    "\n",
    "column_names = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\",\n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"\n",
    "]\n",
    "\n",
    "output_prefix = \"transformed_output.txt\"\n",
    "\n",
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    data = (\n",
    "        p\n",
    "        | 'ReadFromGCS' >> beam.io.ReadFromText(\n",
    "            'gs://customer-churn-storage-bucket/Telco_Customer_Churn.csv', \n",
    "            skip_header_lines=1\n",
    "        )\n",
    "        | 'ParseCSV' >> beam.Map(parse_csv)\n",
    "    )\n",
    "\n",
    "    # Add header row\n",
    "    header_pcoll = p | 'CreateHeader' >> beam.Create([column_names])\n",
    "    full_data = (header_pcoll, data) | 'CombineHeaderWithData' >> beam.Flatten()\n",
    "\n",
    "    # Write to text\n",
    "    full_data | 'WriteToText' >> beam.io.WriteToText(output_prefix, shard_name_template=\"\")\n",
    "\n",
    "print(\"Pipeline execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316db52a-1570-44db-a1fa-1dfcc8d5c2e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moutput_file\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-00000-of-00001\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn Names:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{output_file}-00000-of-00001\", header=None)\n",
    "print(\"Column Names:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6e1e55-f9b0-43e1-bc8a-df4eae32a4ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43moutput_file\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-00000-of-00001\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Show first few rows\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{output_file}-00000-of-00001\", header=None)\n",
    "print(df.head())  # Show first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67432c96-a104-4007-9705-1aa8f3b6e47b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipython', '00-Start_Here.md', 'Tutorials', '.local', '.jupyter', 'transformed_output.txt', '.ipynb_checkpoints', 'Examples', 'assets', '.config', 'faq.md', 'output.txt-00000-of-00001', 'Customer-churn.ipynb', '.cache']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())  # List all files in the directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f399fc-dc3d-4f33-8005-3ef64db3fa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
      "      customerID     gender SeniorCitizen Partner Dependents tenure  \\\n",
      "0  ['7590-VHVEG'   'Female'           '0'   'Yes'       'No'    '1'   \n",
      "1  ['5575-GNVDE'     'Male'           '0'    'No'       'No'   '34'   \n",
      "2  ['3668-QPYBK'     'Male'           '0'    'No'       'No'    '2'   \n",
      "3  ['7795-CFOCW'     'Male'           '0'    'No'       'No'   '45'   \n",
      "4  ['9237-HQITU'   'Female'           '0'    'No'       'No'    '2'   \n",
      "\n",
      "  PhoneService        MultipleLines InternetService OnlineSecurity  ...  \\\n",
      "0         'No'   'No phone service'           'DSL'           'No'  ...   \n",
      "1        'Yes'                 'No'           'DSL'          'Yes'  ...   \n",
      "2        'Yes'                 'No'           'DSL'          'Yes'  ...   \n",
      "3         'No'   'No phone service'           'DSL'          'Yes'  ...   \n",
      "4        'Yes'                 'No'   'Fiber optic'           'No'  ...   \n",
      "\n",
      "  DeviceProtection TechSupport StreamingTV StreamingMovies           Contract  \\\n",
      "0             'No'        'No'        'No'            'No'   'Month-to-month'   \n",
      "1            'Yes'        'No'        'No'            'No'         'One year'   \n",
      "2             'No'        'No'        'No'            'No'   'Month-to-month'   \n",
      "3            'Yes'       'Yes'        'No'            'No'         'One year'   \n",
      "4             'No'        'No'        'No'            'No'   'Month-to-month'   \n",
      "\n",
      "  PaperlessBilling                 PaymentMethod MonthlyCharges TotalCharges  \\\n",
      "0            'Yes'            'Electronic check'        '29.85'      '29.85'   \n",
      "1             'No'                'Mailed check'        '56.95'     '1889.5'   \n",
      "2            'Yes'                'Mailed check'        '53.85'     '108.15'   \n",
      "3             'No'   'Bank transfer (automatic)'         '42.3'    '1840.75'   \n",
      "4            'Yes'            'Electronic check'         '70.7'     '151.65'   \n",
      "\n",
      "     Churn  \n",
      "0    'No']  \n",
      "1    'No']  \n",
      "2   'Yes']  \n",
      "3    'No']  \n",
      "4   'Yes']  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names manually\n",
    "column_names = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\",\n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"\n",
    "]\n",
    "\n",
    "# Read the Beam output file\n",
    "output_file = \"output.txt-00000-of-00001\"  # Make sure this file exists!\n",
    "df = pd.read_csv(output_file, header=None, names=column_names)\n",
    "\n",
    "# Print column names\n",
    "print(\"Column Names:\", df.columns.tolist())\n",
    "\n",
    "# Print first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb986c77-6b50-40a1-b1ec-dc00c6e348da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation complete.\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "# Define pipeline options\n",
    "pipeline_options = PipelineOptions([\n",
    "    '--runner=DirectRunner'  # Use DirectRunner for local execution\n",
    "])\n",
    "\n",
    "# Define column names\n",
    "column_names = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\",\n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"\n",
    "]\n",
    "\n",
    "# Function to parse CSV row\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    from io import StringIO\n",
    "    reader = csv.reader(StringIO(line))\n",
    "    return next(reader)  # Returns a list of values\n",
    "\n",
    "# Function to clean & transform data\n",
    "def transform_data(row):\n",
    "    try:\n",
    "        # Convert to dictionary\n",
    "        data = dict(zip(column_names, row))\n",
    "\n",
    "        # Convert 'TotalCharges' to numeric (handle missing values)\n",
    "        try:\n",
    "            data[\"TotalCharges\"] = float(data[\"TotalCharges\"]) if data[\"TotalCharges\"].strip() else 0.0\n",
    "        except ValueError:\n",
    "            data[\"TotalCharges\"] = 0.0\n",
    "\n",
    "        # Convert binary categorical columns (Yes/No → 1/0)\n",
    "        binary_cols = [\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\", \"Churn\"]\n",
    "        for col in binary_cols:\n",
    "            data[col] = 1 if data[col].strip().lower() == \"yes\" else 0\n",
    "\n",
    "        # One-Hot Encode multi-class categorical variables\n",
    "        one_hot_cols = [\"InternetService\", \"Contract\", \"PaymentMethod\"]\n",
    "        for col in one_hot_cols:\n",
    "            value = data[col].replace(\" \", \"_\").lower()  # Normalize column names\n",
    "            data[f\"{col}_{value}\"] = 1  # One-hot encode\n",
    "            del data[col]  # Remove original column\n",
    "\n",
    "        # Convert 'SeniorCitizen' to categorical\n",
    "        data[\"SeniorCitizen\"] = int(data[\"SeniorCitizen\"])\n",
    "\n",
    "        # Feature Engineering: AvgMonthlySpend = TotalCharges / tenure\n",
    "        tenure = int(data[\"tenure\"])\n",
    "        data[\"AvgMonthlySpend\"] = round(data[\"TotalCharges\"] / tenure, 2) if tenure > 0 else 0.0\n",
    "\n",
    "        # Create tenure groups\n",
    "        if tenure < 12:\n",
    "            data[\"TenureGroup\"] = \"New\"\n",
    "        elif 12 <= tenure < 48:\n",
    "            data[\"TenureGroup\"] = \"Medium\"\n",
    "        else:\n",
    "            data[\"TenureGroup\"] = \"LongTerm\"\n",
    "\n",
    "        # Scale continuous variables (Min-Max Scaling)\n",
    "        data[\"MonthlyCharges\"] = round(float(data[\"MonthlyCharges\"]) / 100, 2)\n",
    "        data[\"TotalCharges\"] = round(float(data[\"TotalCharges\"]) / 10000, 4)\n",
    "\n",
    "        return data  # Return transformed data as dictionary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row} - {e}\")\n",
    "        return None\n",
    "\n",
    "# Define Apache Beam pipeline\n",
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    transformed_data = (\n",
    "        p\n",
    "        | 'ReadFromGCS' >> beam.io.ReadFromText(\n",
    "            'gs://customer-churn-storage-bucket/Telco_Customer_Churn.csv', \n",
    "            skip_header_lines=1\n",
    "        )\n",
    "        | 'ParseCSV' >> beam.Map(parse_csv)\n",
    "        | 'TransformData' >> beam.Map(transform_data)\n",
    "        | 'RemoveNone' >> beam.Filter(lambda x: x is not None)  # Remove failed transformations\n",
    "        | 'WriteToText' >> beam.io.WriteToText(\"transformed_output.txt\", shard_name_template=\"\")\n",
    "    )\n",
    "\n",
    "print(\"Data transformation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a812489d-8c6d-4bec-a0a4-144953abd081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia-southeast1-b          asia-southeast1          UP\n",
      "asia-southeast1-a          asia-southeast1          UP\n",
      "asia-southeast1-c          asia-southeast1          UP\n"
     ]
    }
   ],
   "source": [
    "!gcloud compute zones list | grep asia-southeast1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15ebf442-f166-49d5-ba87-2ffa381b1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset customer-churn-451414.customer_churn_data already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation complete. Check transformed_output.txt for debugging.\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.io.gcp.bigquery import WriteToBigQuery, BigQueryDisposition\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Define pipeline options\n",
    "pipeline_options = PipelineOptions([\n",
    "    '--runner=DirectRunner',\n",
    "    '--project=customer-churn-451414',\n",
    "    '--temp_location=gs://customer-churn-storage-bucket/temp',\n",
    "])\n",
    "\n",
    "# Define column names\n",
    "column_names = [\n",
    "    \"customerID\", \"gender\", \"SeniorCitizen\", \"Partner\", \"Dependents\",\n",
    "    \"tenure\", \"PhoneService\", \"MultipleLines\", \"InternetService\",\n",
    "    \"OnlineSecurity\", \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\",\n",
    "    \"StreamingTV\", \"StreamingMovies\", \"Contract\", \"PaperlessBilling\",\n",
    "    \"PaymentMethod\", \"MonthlyCharges\", \"TotalCharges\", \"Churn\"\n",
    "]\n",
    "\n",
    "# Function to parse CSV row\n",
    "def parse_csv(line):\n",
    "    import csv\n",
    "    from io import StringIO\n",
    "    reader = csv.reader(StringIO(line))\n",
    "    return next(reader)\n",
    "\n",
    "# Function to clean & transform data (updated to ensure all one-hot fields are present)\n",
    "def transform_data(row):\n",
    "    try:\n",
    "        data = dict(zip(column_names, row))\n",
    "        try:\n",
    "            data[\"TotalCharges\"] = float(data[\"TotalCharges\"]) if data[\"TotalCharges\"].strip() else 0.0\n",
    "        except ValueError:\n",
    "            data[\"TotalCharges\"] = 0.0\n",
    "        binary_cols = [\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\", \"Churn\"]\n",
    "        for col in binary_cols:\n",
    "            data[col] = 1 if data[col].strip().lower() == \"yes\" else 0\n",
    "        \n",
    "        # Define all possible one-hot encoded values and initialize to 0\n",
    "        one_hot_values = {\n",
    "            \"InternetService\": [\"dsl\", \"fiber_optic\", \"no\"],\n",
    "            \"Contract\": [\"month-to-month\", \"one_year\", \"two_year\"],\n",
    "            \"PaymentMethod\": [\"electronic_check\", \"mailed_check\", \"bank_transfer_automatic\", \"credit_card_automatic\"]\n",
    "        }\n",
    "        \n",
    "        # Initialize all one-hot fields to 0\n",
    "        for col, values in one_hot_values.items():\n",
    "            for value in values:\n",
    "                data[f\"{col}_{value}\"] = 0\n",
    "        \n",
    "        # Set the actual one-hot encoded value to 1\n",
    "        one_hot_cols = [\"InternetService\", \"Contract\", \"PaymentMethod\"]\n",
    "        for col in one_hot_cols:\n",
    "            value = data[col].replace(\" \", \"_\").replace(\"(\", \"_\").replace(\")\", \"_\").lower()\n",
    "            if f\"{col}_{value}\" in data:  # Ensure the key exists in the initialized set\n",
    "                data[f\"{col}_{value}\"] = 1\n",
    "            del data[col]\n",
    "        \n",
    "        data[\"SeniorCitizen\"] = int(data[\"SeniorCitizen\"])\n",
    "        tenure = int(data[\"tenure\"])\n",
    "        data[\"AvgMonthlySpend\"] = round(data[\"TotalCharges\"] / tenure, 2) if tenure > 0 else 0.0\n",
    "        if tenure < 12:\n",
    "            data[\"TenureGroup\"] = \"New\"\n",
    "        elif 12 <= tenure < 48:\n",
    "            data[\"TenureGroup\"] = \"Medium\"\n",
    "        else:\n",
    "            data[\"TenureGroup\"] = \"LongTerm\"\n",
    "        data[\"MonthlyCharges\"] = round(float(data[\"MonthlyCharges\"]) / 100, 2)\n",
    "        data[\"TotalCharges\"] = round(float(data[\"TotalCharges\"]) / 10000, 4)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row: {row} - {e}\")\n",
    "        return None\n",
    "\n",
    "# Define BigQuery schema\n",
    "bq_schema = {\n",
    "    \"fields\": [\n",
    "        {\"name\": \"customerID\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"gender\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"SeniorCitizen\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"Partner\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"Dependents\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"tenure\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"PhoneService\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"MultipleLines\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"OnlineSecurity\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"OnlineBackup\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"DeviceProtection\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"TechSupport\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"StreamingTV\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"StreamingMovies\", \"type\": \"STRING\"},\n",
    "        {\"name\": \"PaperlessBilling\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"MonthlyCharges\", \"type\": \"FLOAT\"},\n",
    "        {\"name\": \"TotalCharges\", \"type\": \"FLOAT\"},\n",
    "        {\"name\": \"Churn\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"InternetService_dsl\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"InternetService_fiber_optic\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"InternetService_no\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"Contract_month-to-month\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"Contract_one_year\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"Contract_two_year\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"PaymentMethod_electronic_check\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"PaymentMethod_mailed_check\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"PaymentMethod_bank_transfer_automatic\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"PaymentMethod_credit_card_automatic\", \"type\": \"INTEGER\"},\n",
    "        {\"name\": \"AvgMonthlySpend\", \"type\": \"FLOAT\"},\n",
    "        {\"name\": \"TenureGroup\", \"type\": \"STRING\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to create the BigQuery dataset if it doesn’t exist\n",
    "def create_dataset(project_id, dataset_id, location=\"asia-southeast1\"):\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    dataset_ref = f\"{project_id}.{dataset_id}\"\n",
    "    try:\n",
    "        client.get_dataset(dataset_ref)\n",
    "        print(f\"Dataset {dataset_ref} already exists.\")\n",
    "    except Exception:\n",
    "        dataset = bigquery.Dataset(dataset_ref)\n",
    "        dataset.location = location\n",
    "        client.create_dataset(dataset)\n",
    "        print(f\"Created dataset {dataset_ref} in location {location}.\")\n",
    "\n",
    "# Create the dataset before running the pipeline\n",
    "create_dataset(\"customer-churn-451414\", \"customer_churn_data\", \"asia-southeast1\")\n",
    "\n",
    "# Define Apache Beam pipeline\n",
    "with beam.Pipeline(options=pipeline_options) as p:\n",
    "    transformed_data = (\n",
    "        p\n",
    "        | 'ReadFromGCS' >> beam.io.ReadFromText(\n",
    "            'gs://customer-churn-storage-bucket/Telco_Customer_Churn.csv', \n",
    "            skip_header_lines=1\n",
    "        )\n",
    "        | 'ParseCSV' >> beam.Map(parse_csv)\n",
    "        | 'TransformData' >> beam.Map(transform_data)\n",
    "        | 'RemoveNone' >> beam.Filter(lambda x: x is not None)\n",
    "        # Temporarily write to text for debugging\n",
    "        | 'WriteToText' >> beam.io.WriteToText(\"transformed_output.txt\", shard_name_template=\"\")\n",
    "        # Uncomment the line below after verifying the output\n",
    "        #| 'WriteToBigQuery' >> WriteToBigQuery(\n",
    "             #table='customer-churn-451414:customer_churn_data.customer_churn',\n",
    "             #schema=bq_schema,\n",
    "             #write_disposition=BigQueryDisposition.WRITE_TRUNCATE,\n",
    "             #create_disposition=BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "             #custom_gcs_temp_location='gs://customer-churn-storage-bucket/temp'\n",
    "         #)\n",
    "    )\n",
    "\n",
    "print(\"Data transformation complete. Check transformed_output.txt for debugging.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5338fc3-fafb-4c73-b073-7d5f783db19d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://customer-churn-storage-bucket/temp/bq_load/d69da035646a4e0d96538b6ed8431e1e/customer-churn-451414.customer_churn_data.customer_churn/5768159a-05bb-478c-acd9-3ef213193b7e...\n",
      "/ [1 files][  3.7 MiB/  3.7 MiB]                                                \n",
      "Operation completed over 1 objects/3.7 MiB.                                      \n",
      "{\"customerID\": \"7590-VHVEG\", \"gender\": \"Female\", \"SeniorCitizen\": 0, \"Partner\": 1, \"Dependents\": 0, \"tenure\": \"1\", \"PhoneService\": 0, \"MultipleLines\": \"No phone service\", \"OnlineSecurity\": \"No\", \"OnlineBackup\": \"Yes\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.3, \"TotalCharges\": 0.003, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_electronic_check\": 1, \"AvgMonthlySpend\": 29.85, \"TenureGroup\": \"New\"}\n",
      "{\"customerID\": \"5575-GNVDE\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"34\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"Yes\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 0, \"MonthlyCharges\": 0.57, \"TotalCharges\": 0.189, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_one_year\": 1, \"PaymentMethod_mailed_check\": 1, \"AvgMonthlySpend\": 55.57, \"TenureGroup\": \"Medium\"}\n",
      "{\"customerID\": \"3668-QPYBK\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"2\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"Yes\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.54, \"TotalCharges\": 0.0108, \"Churn\": 1, \"InternetService_dsl\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_mailed_check\": 1, \"AvgMonthlySpend\": 54.08, \"TenureGroup\": \"New\"}\n",
      "{\"customerID\": \"7795-CFOCW\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"45\", \"PhoneService\": 0, \"MultipleLines\": \"No phone service\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"Yes\", \"TechSupport\": \"Yes\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 0, \"MonthlyCharges\": 0.42, \"TotalCharges\": 0.1841, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_one_year\": 1, \"PaymentMethod_bank_transfer__automatic_\": 1, \"AvgMonthlySpend\": 40.91, \"TenureGroup\": \"Medium\"}\n",
      "{\"customerID\": \"9237-HQITU\", \"gender\": \"Female\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"2\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"No\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.71, \"TotalCharges\": 0.0152, \"Churn\": 1, \"InternetService_fiber_optic\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_electronic_check\": 1, \"AvgMonthlySpend\": 75.83, \"TenureGroup\": \"New\"}\n"
     ]
    }
   ],
   "source": [
    "# Download the file locally\n",
    "!gsutil cp gs://customer-churn-storage-bucket/temp/bq_load/d69da035646a4e0d96538b6ed8431e1e/customer-churn-451414.customer_churn_data.customer_churn/5768159a-05bb-478c-acd9-3ef213193b7e temp.json\n",
    "\n",
    "# Display the first 5 lines\n",
    "with open(\"temp.json\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 5:\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e50a23e-b6f6-4caf-9947-46d0c52d2543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://customer-churn-storage-bucket/temp/bq_load/d69da035646a4e0d96538b6ed8431e1e/customer-churn-451414.customer_churn_data.customer_churn/5768159a-05bb-478c-acd9-3ef213193b7e...\n",
      "/ [1 files][  3.7 MiB/  3.7 MiB]                                                \n",
      "Operation completed over 1 objects/3.7 MiB.                                      \n",
      "{\"customerID\": \"7590-VHVEG\", \"gender\": \"Female\", \"SeniorCitizen\": 0, \"Partner\": 1, \"Dependents\": 0, \"tenure\": \"1\", \"PhoneService\": 0, \"MultipleLines\": \"No phone service\", \"OnlineSecurity\": \"No\", \"OnlineBackup\": \"Yes\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.3, \"TotalCharges\": 0.003, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_electronic_check\": 1, \"AvgMonthlySpend\": 29.85, \"TenureGroup\": \"New\"}\n",
      "{\"customerID\": \"5575-GNVDE\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"34\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"Yes\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 0, \"MonthlyCharges\": 0.57, \"TotalCharges\": 0.189, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_one_year\": 1, \"PaymentMethod_mailed_check\": 1, \"AvgMonthlySpend\": 55.57, \"TenureGroup\": \"Medium\"}\n",
      "{\"customerID\": \"3668-QPYBK\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"2\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"Yes\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.54, \"TotalCharges\": 0.0108, \"Churn\": 1, \"InternetService_dsl\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_mailed_check\": 1, \"AvgMonthlySpend\": 54.08, \"TenureGroup\": \"New\"}\n",
      "{\"customerID\": \"7795-CFOCW\", \"gender\": \"Male\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"45\", \"PhoneService\": 0, \"MultipleLines\": \"No phone service\", \"OnlineSecurity\": \"Yes\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"Yes\", \"TechSupport\": \"Yes\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 0, \"MonthlyCharges\": 0.42, \"TotalCharges\": 0.1841, \"Churn\": 0, \"InternetService_dsl\": 1, \"Contract_one_year\": 1, \"PaymentMethod_bank_transfer__automatic_\": 1, \"AvgMonthlySpend\": 40.91, \"TenureGroup\": \"Medium\"}\n",
      "{\"customerID\": \"9237-HQITU\", \"gender\": \"Female\", \"SeniorCitizen\": 0, \"Partner\": 0, \"Dependents\": 0, \"tenure\": \"2\", \"PhoneService\": 1, \"MultipleLines\": \"No\", \"OnlineSecurity\": \"No\", \"OnlineBackup\": \"No\", \"DeviceProtection\": \"No\", \"TechSupport\": \"No\", \"StreamingTV\": \"No\", \"StreamingMovies\": \"No\", \"PaperlessBilling\": 1, \"MonthlyCharges\": 0.71, \"TotalCharges\": 0.0152, \"Churn\": 1, \"InternetService_fiber_optic\": 1, \"Contract_month-to-month\": 1, \"PaymentMethod_electronic_check\": 1, \"AvgMonthlySpend\": 75.83, \"TenureGroup\": \"New\"}\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://customer-churn-storage-bucket/temp/bq_load/d69da035646a4e0d96538b6ed8431e1e/customer-churn-451414.customer_churn_data.customer_churn/5768159a-05bb-478c-acd9-3ef213193b7e temp.json\n",
    "with open(\"temp.json\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < 5:\n",
    "            print(line.strip())\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c19ed389-42fd-49b5-a36e-4efe69d5161d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "bq_schema = [\n",
    "    {\"name\": \"customerID\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"gender\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"SeniorCitizen\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"Partner\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"Dependents\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"tenure\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"PhoneService\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"MultipleLines\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"OnlineSecurity\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"OnlineBackup\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"DeviceProtection\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"TechSupport\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"StreamingTV\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"StreamingMovies\", \"type\": \"STRING\"},\n",
    "    {\"name\": \"PaperlessBilling\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"MonthlyCharges\", \"type\": \"FLOAT\"},\n",
    "    {\"name\": \"TotalCharges\", \"type\": \"FLOAT\"},\n",
    "    {\"name\": \"Churn\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"InternetService_dsl\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"InternetService_fiber_optic\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"InternetService_no\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"Contract_month-to-month\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"Contract_one_year\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"Contract_two_year\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"PaymentMethod_electronic_check\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"PaymentMethod_mailed_check\", \"type\": \"INTEGER\"},\n",
    "    {\"name\": \"PaymentMethod_bank_transfer__automatic_\", \"type\": \"INTEGER\"},  # Double underscore\n",
    "    {\"name\": \"PaymentMethod_credit_card__automatic_\", \"type\": \"INTEGER\"},    # Double underscore\n",
    "    {\"name\": \"AvgMonthlySpend\", \"type\": \"FLOAT\"},\n",
    "    {\"name\": \"TenureGroup\", \"type\": \"STRING\"}\n",
    "]\n",
    "\n",
    "with open(\"bq_schema.json\", \"w\") as f:\n",
    "    json.dump(bq_schema, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc38587c-7e1e-4a82-becf-b2a39b4be6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r5e5b89642efeba7a_0000019547d4f119_1 ... (1s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq load \\\n",
    "  --source_format=NEWLINE_DELIMITED_JSON \\\n",
    "  customer-churn-451414:customer_churn_data.customer_churn \\\n",
    "  gs://customer-churn-storage-bucket/temp/bq_load/d69da035646a4e0d96538b6ed8431e1e/customer-churn-451414.customer_churn_data.customer_churn/5768159a-05bb-478c-acd9-3ef213193b7e \\\n",
    "  ./bq_schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010a62e0-49dc-42d4-b500-1f62b3c67800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "apache-beam-2.61.0",
   "name": ".m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m127"
  },
  "kernelspec": {
   "display_name": "Apache Beam 2.61.0 (Local)",
   "language": "python",
   "name": "apache-beam-2.61.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
